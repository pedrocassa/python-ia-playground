{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b7bdcf-3012-4aa7-8bcc-0019234cc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "with open(\"artigoLLMs.txt\", 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1200, chunk_overlap=100)\n",
    "\n",
    "texts = text_splitter.split_text(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacb9925-3cba-49ff-a36c-17e6cb92ee1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m-Goal-\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m \u001b[33moutput:\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    125\u001b[39m prompt = ChatPromptTemplate.from_template(prompt_template)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Pedro\\python-ia-playground\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Pedro\\python-ia-playground\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:622\u001b[39m, in \u001b[36mBaseChatOpenAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    618\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_client = httpx.Client(\n\u001b[32m    619\u001b[39m             proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy, verify=global_ssl_context\n\u001b[32m    620\u001b[39m         )\n\u001b[32m    621\u001b[39m     sync_specific = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client}\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m     \u001b[38;5;28mself\u001b[39m.root_client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28mself\u001b[39m.root_client.chat.completions\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Pedro\\python-ia-playground\\.venv\\Lib\\site-packages\\openai\\_client.py:116\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    114\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Falta uma chave para utilziar essa api\n",
    "# Rodei esse prompt com o artigoLLM.txt para continuar com o experimento\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "-Goal-\n",
    "Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: One of the following types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\"{{tuple_delimiter}}<entity_name>{{tuple_delimiter}}<entity_type>{{tuple_delimiter}}<entity_description>)\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "- relationship_strength: an integer score between 1 to 10, indicating strength of the relationship between the source entity and target entity\n",
    "Format each relationship as (\"relationship\"{{tuple_delimiter}}<source_entity>{{tuple_delimiter}}<target_entity>{{tuple_delimiter}}<relationship_description>{{tuple_delimiter}}<relationship_strength>)\n",
    "\n",
    "3. Return output in The primary language of the provided text is \"English.\" as a single list of all the entities and relationships identified in steps 1 and 2. Use **{{record_delimiter}}** as the list delimiter.\n",
    "\n",
    "4. If you have to translate into The primary language of the provided text is \"English.\", just translate the descriptions, nothing else!\n",
    "\n",
    "5. When finished, output {{completion_delimiter}}.\n",
    "\n",
    "-Examples-\n",
    "######################\n",
    "\n",
    "Example 1:\n",
    "\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text:\n",
    " LLMs to create synthetic samples that mimic clients’ private data distribution using\n",
    "differential privacy. This approach significantly boosts SLMs’ performance by approximately 5% while\n",
    "maintaining data privacy with a minimal privacy budget, outperforming traditional methods relying\n",
    "solely on local private data.\n",
    "In healthcare, federated fine-tuning can allow hospitals to collaboratively train models on patient data\n",
    "without transferring sensitive information. This approach ensures data privacy while enabling the de-\n",
    "velopment of robust, generalisable AI systems.\n",
    "8https://ai.meta.com/responsible-ai/\n",
    "9https://huggingface.co/docs/hub/en/model-cards\n",
    "10https://www.tensorflow.org/responsible_ai/privacy/guide\n",
    "101 Frameworks for Enhancing Security\n",
    "Adversarial training and robust security measures[111] are essential for protecting fine-tuned models\n",
    "against attacks. The adversarial training approach involves training models with adversarial examples\n",
    "to improve their resilience against malicious inputs. Microsoft Azure’s\n",
    "------------------------\n",
    "output:\n",
    "(\"entity\"{{tuple_delimiter}}DIFFERENTIAL PRIVACY{{tuple_delimiter}}differential privacy{{tuple_delimiter}}Differential privacy is a technique used to create synthetic samples that mimic clients' private data distribution while maintaining data privacy with a minimal privacy budget{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}HEALTHCARE{{tuple_delimiter}}healthcare{{tuple_delimiter}}In healthcare, federated fine-tuning allows hospitals to collaboratively train models on patient data without transferring sensitive information, ensuring data privacy{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}federated learning{{tuple_delimiter}}Federated learning is a method that enables collaborative model training on decentralized data sources, such as hospitals, without sharing sensitive information{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}ADVERSARIAL TRAINING{{tuple_delimiter}}adversarial training{{tuple_delimiter}}Adversarial training involves training models with adversarial examples to improve their resilience against malicious inputs{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}SECURITY MEASURES{{tuple_delimiter}}security measures{{tuple_delimiter}}Robust security measures are essential for protecting fine-tuned models against attacks{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}DIFFERENTIAL PRIVACY{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}Differential privacy is used in federated learning to maintain data privacy while training models collaboratively{{tuple_delimiter}}8{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}HEALTHCARE{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}Federated learning is applied in healthcare to train models on patient data without transferring sensitive information{{tuple_delimiter}}9{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ADVERSARIAL TRAINING{{tuple_delimiter}}SECURITY MEASURES{{tuple_delimiter}}Adversarial training is a security measure used to protect models against attacks by improving their resilience{{tuple_delimiter}}8{{completion_delimiter}}\n",
    "#############################\n",
    "\n",
    "\n",
    "Example 2:\n",
    "\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text:\n",
    "ARD [82] is an innovative open-source tool developed to enhance the safety of interactions\n",
    "with large language models (LLMs). This tool addresses three critical moderation tasks: detecting\n",
    "2https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForCausalLM\n",
    "63 harmful intent in user prompts, identifying safety risks in model responses, and determining when a\n",
    "model appropriately refuses unsafe requests. Central to its development is WILDGUARD MIX3, a\n",
    "meticulously curated dataset comprising 92,000 labelled examples that include both benign prompts and\n",
    "adversarial attempts to bypass safety measures. The dataset is divided into WILDGUARD TRAIN, used\n",
    "for training the model, and WILDGUARD TEST, consisting of high-quality human-annotated examples\n",
    "for evaluation.\n",
    "The WILDGUARD model itself is fine-tuned on the Mistral-7B language model using the WILDGUARD\n",
    "TRAIN dataset, enabling it to perform all\n",
    "------------------------\n",
    "output:\n",
    "```plaintext\n",
    "(\"entity\"{{tuple_delimiter}}ARD{{tuple_delimiter}}open-source tool{{tuple_delimiter}}ARD is an innovative open-source tool developed to enhance the safety of interactions with large language models by addressing moderation tasks such as detecting harmful intent, identifying safety risks, and determining appropriate refusals of unsafe requests)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}LARGE LANGUAGE MODELS{{tuple_delimiter}}large language model{{tuple_delimiter}}Large language models (LLMs) are advanced AI models designed to understand and generate human-like text, which ARD aims to interact with safely)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD MIX3 is a meticulously curated dataset comprising 92,000 labeled examples, including benign prompts and adversarial attempts, used for training and evaluating safety measures in language models)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD TRAIN is a subset of the WILDGUARD MIX3 dataset used specifically for training the model on safety measures)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD TEST{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD TEST is a subset of the WILDGUARD MIX3 dataset consisting of high-quality human-annotated examples used for evaluating the model's performance)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}MISTRAL-7B{{tuple_delimiter}}large language model{{tuple_delimiter}}Mistral-7B is a language model that the WILDGUARD model is fine-tuned on using the WILDGUARD TRAIN dataset to enhance its safety performance)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}ADVERSARIAL ATTEMPTS{{tuple_delimiter}}adversarial training{{tuple_delimiter}}Adversarial attempts are part of the WILDGUARD MIX3 dataset, used to test and improve the model's ability to handle unsafe or harmful inputs)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}SAFETY MEASURES{{tuple_delimiter}}security measures{{tuple_delimiter}}Safety measures are protocols and techniques implemented to ensure that large language models interact safely with users, which ARD and the WILDGUARD dataset aim to enhance)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ARD{{tuple_delimiter}}LARGE LANGUAGE MODELS{{tuple_delimiter}}ARD is designed to enhance the safety of interactions with large language models by addressing critical moderation tasks{{tuple_delimiter}}8)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ARD{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}ARD uses the WILDGUARD MIX3 dataset to train and evaluate its moderation capabilities{{tuple_delimiter}}7)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}WILDGUARD TRAIN is a subset of the WILDGUARD MIX3 dataset used for training{{tuple_delimiter}}9)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}WILDGUARD TEST{{tuple_delimiter}}WILDGUARD TEST is a subset of the WILDGUARD MIX3 dataset used for evaluation{{tuple_delimiter}}9)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}MISTRAL-7B{{tuple_delimiter}}The WILDGUARD TRAIN dataset is used to fine-tune the Mistral-7B language model{{tuple_delimiter}}8)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ADVERSARIAL ATTEMPTS{{tuple_delimiter}}SAFETY MEASURES{{tuple_delimiter}}Adversarial attempts are used to test and improve safety measures in language models{{tuple_delimiter}}7)\n",
    "{{completion_delimiter}}\n",
    "```\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text: {input_text}\n",
    "######################\n",
    "output:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc14bd2-a00a-464c-bf8e-20bad493ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
